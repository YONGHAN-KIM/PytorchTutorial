{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- https://tensorboard-pytorch.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:55.635196Z",
     "start_time": "2018-10-30T04:13:55.131893Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as vdatasets\n",
    "import torchvision.utils as vutils\n",
    "import pickle\n",
    "import os, shutil\n",
    "\n",
    "torch.manual_seed(1)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is TensorBoardX?\n",
    "- 구글의 tensorflow는 neural network의 훈련 과정을 시각화할 수 있는 tensorboard라는  웹서버가 있다. 이 tensorboard는 scalar, image, text 등을 정보를 시각화해준다. 하지만 pytorch같은 다른 딥러닝 프레임워크는 tensorboard와 같은 툴이 없다. \n",
    "- 그래서 tensorflow가 아닌 pytorch도 tensorboard의 기본적인 기능을 사용할 수 있게 해주는게 tensorboardX이다.\n",
    "- 현재는 scalar, image, audio, histogram, text, embedding, route of backpropagation을 지원하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorboardX 사용법\n",
    "## 0.port 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:55.652508Z",
     "start_time": "2018-10-30T04:13:55.646162Z"
    }
   },
   "outputs": [],
   "source": [
    "# 텐서보드 포트 설정\n",
    "port= '6006'\n",
    "\n",
    "# 텐서보드 데이터 파일 초기화\n",
    "try:\n",
    "    shutil.rmtree('runs/')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:55.817145Z",
     "start_time": "2018-10-30T04:13:55.811609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6006'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. create a summary writer\n",
    "-  logging을 하기 전에 writer instance를 생성해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:56.682360Z",
     "start_time": "2018-10-30T04:13:56.626800Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "#SummaryWriter encapsulates everything\n",
    "writer = SummaryWriter('runs/exp-1')\n",
    "#creates writer object. The log will be saved in 'runs/exp-1'\n",
    "writer2 = SummaryWriter()\n",
    "#creates writer2 object with auto generated file name, the dir will be something like 'runs/Aug20-17-20-33'\n",
    "writer3 = SummaryWriter(comment='3x learning rate')\n",
    "#creates writer2 object with auto generated file name, the comment will be appended to the filename. The dir will be something like 'runs/Aug20-17-20-33-3xlearning rate'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. add_\n",
    "- logging할 정보를 입력한다.\n",
    "\n",
    "### general api format\n",
    "- add_something(tag_name, object, iteration number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 add_scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:57.310832Z",
     "start_time": "2018-10-30T04:13:57.306553Z"
    }
   },
   "outputs": [],
   "source": [
    "writer= SummaryWriter('runs/add_scalar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:57.740108Z",
     "start_time": "2018-10-30T04:13:57.691124Z"
    }
   },
   "outputs": [],
   "source": [
    "for n_iter in range(100):\n",
    "    s1= torch.rand(1)\n",
    "    s2= torch.rand(1)\n",
    "    writer.add_scalar('data/scalar1', s1[0], n_iter) # data grouping by 'slash'\n",
    "    writer.add_scalars('data/scalar_group', {'xsinx':n_iter*np.sin(n_iter),\n",
    "                                            'xcosx':n_iter*np.cos(n_iter),\n",
    "                                            'arctan':np.arctan(n_iter)}, n_iter)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:58.278787Z",
     "start_time": "2018-10-30T04:13:58.274653Z"
    }
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.linear1= nn.Linear(1024, 512)\n",
    "        self.linear2= nn.Linear(512, 512)\n",
    "        self.linear3= nn.Linear(512, 10)\n",
    "        \n",
    "        # In : {배치사이즈, 차원수} => Out : (배치사이즈, 차원수)\n",
    "        self.bn1= nn.BatchNorm1d(512)\n",
    "        self.bn2= nn.BatchNorm1d(512)\n",
    "    def forward(self, inputs):\n",
    "        outputs= self.bn1(self.linear1(inputs))\n",
    "        outputs= F.relu(outputs)\n",
    "        outputs= self.bn2(self.linear2(outputs))\n",
    "        outputs= F.relu(outputs)\n",
    "        return self.linear3(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:13:58.595117Z",
     "start_time": "2018-10-30T04:13:58.563050Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model= NN()\n",
    "test_inputs= torch.randn(64,1024, requires_grad=True)\n",
    "outputs= model(test_inputs)\n",
    "\n",
    "writer.add_graph(model, (test_inputs, ))  # , verbose=True)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-30T04:18:11.799051Z",
     "start_time": "2018-10-30T04:17:51.175645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "# demo.py\n",
    "\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "resnet18 = models.resnet18(False)\n",
    "writer= SummaryWriter(log_dir='resnet')\n",
    "sample_rate = 44100\n",
    "freqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n",
    "\n",
    "\n",
    "for n_iter in range(100):\n",
    "\n",
    "    dummy_s1 = torch.rand(1)\n",
    "    dummy_s2 = torch.rand(1)\n",
    "    # data grouping by `slash`\n",
    "    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)\n",
    "    writer.add_scalar('data/scalar2', dummy_s2[0], n_iter)\n",
    "\n",
    "    writer.add_scalars('data/scalar_group', {'xsinx': n_iter * np.sin(n_iter),\n",
    "                                             'xcosx': n_iter * np.cos(n_iter),\n",
    "                                             'arctanx': np.arctan(n_iter)}, n_iter)\n",
    "\n",
    "    dummy_img = torch.rand(32, 3, 64, 64)  # output from network\n",
    "    if n_iter % 10 == 0:\n",
    "        x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)\n",
    "        writer.add_image('Image', x, n_iter)\n",
    "\n",
    "        dummy_audio = torch.zeros(sample_rate * 2)\n",
    "        for i in range(x.size(0)):\n",
    "            # amplitude of sound should in [-1, 1]\n",
    "            dummy_audio[i] = np.cos(freqs[n_iter // 10] * np.pi * float(i) / float(sample_rate))\n",
    "        writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)\n",
    "\n",
    "        writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)\n",
    "\n",
    "        for name, param in resnet18.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)\n",
    "\n",
    "        # needs tensorboard 0.4RC or later\n",
    "        writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)\n",
    "\n",
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:100].float()\n",
    "label = dataset.test_labels[:100]\n",
    "\n",
    "features = images.view(100, 784)\n",
    "writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n",
    "\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir runs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
