{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목차\n",
    "1. What is a Regularization?\n",
    "2. Parameter Norm Penalties\n",
    " - 2.1 L2 Parameter Regularization\n",
    " - 2.2 L1 Parameter Regularization\n",
    "3. Drop out\n",
    "4. Early Stopping\n",
    "\n",
    "## 1. What is a Regularization?\n",
    " - Regularization이란 모델에 generalization error(training error가 아닌)를 줄이는 것이다.\n",
    " \n",
    "<img src='./images/regularization.png' width=500>  \n",
    "\n",
    "## 2. Parameter Norm Penalties\n",
    "- 많은 regularization기법들은 parameter norm penalty들을 더해 model의 크기를 제한한다.\n",
    "- object function을 $J$라고 하고 , parameter norm penalty를 $\\Omega$라고 한다면 정규화된 obejct fuction은 다음과 같다.($\\alpha$는 hyper param으로 norm penalty의 크기를 조절해줌.)\n",
    "$$ \\widetilde{J(w; X, y)} = J(w; X, y) +\\alpha\\Omega(w)$$\n",
    "- 일반적으로 bias들을 제외한 affine transform weight들만 penalize한다.\n",
    "- bias를 penalize하면 underfitting에 원인이 될 수 있다.\n",
    "\n",
    "<img src='./images/l2.png' width=300>  \n",
    "\n",
    "그림을 보면 실선은 정규화되지 않은 objective function의 값이다. 그리고 점선은 정규화 값이다.  가로 축에서는 objective function이 크게 변하지 않는다. 그 이유는 objective function에서 중요한 feature가 아니기 떄문이다. 그래서 이 축은 regularizer가 강한 효과를 가진다. Regularizersms w1을 0에 가깝게 당긴다. 하지만 세로 축에서는 objective function 변화가 크게 일어난다. 그래서 w2는 상대적으로 감소 하는 영향을 작게 받는다.\n",
    "결론적으로, 중요한 feature에 대해서는 weight를 크게 줄이지 않고, 중요하지 않은 feature는 weight를 크게 감소시킨다.\n",
    "\n",
    "### 2.1 L2 Parameter Regularization\n",
    "- 일반적으로 가장 많이 사용됨.\n",
    "- 모든 파라미터 제곱 만큼의 크기를 object function에 제약을 주는 방법.\n",
    "$$ \\widetilde{J(w; X, y)} = J(w; X, y) + \\frac{1}{2}\\alpha w^{T}w $$\n",
    "\n",
    "<img src='./images/ridge.png' width=400>  \n",
    "\n",
    "- gradient를 계산하면 아래와 같음.\n",
    "$$ \\bigtriangledown_{w}\\widetilde{J(w; X, y)} = \\bigtriangledown_{w} J(w; X, y) +\\alpha * w $$\n",
    "\n",
    "\n",
    "### 2.2 L1 Parameter Regularization\n",
    "- 모든 weight의 절대값 만큼의 크기를 object function에 제약을 주는 방법.\n",
    "$$ \\widetilde{J(w; X, y)} = J(w; X, y) + \\alpha |w| $$\n",
    "\n",
    "- L1 regularization은 optimization 과정 동안 weight들을 sparse하게 만드는 효과가 있음. \n",
    "- feature selection 효과가 있음.\n",
    "<img src='./images/lasso.png' width=500>  \n",
    "\n",
    "- gradient를 계산하면 아래와 같음.\n",
    "$$ \\bigtriangledown_{w}\\widetilde{J(w; X, y)} = \\bigtriangledown_{w} J(w; X, y) + \\alpha sign(w)  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Drop out\n",
    "- 딥러닝에서 사용하는 Regularization 기법 중 하나임.\n",
    "- 학습을 할 때 forward pass시 랜덤하게 일정 확률 만큼의 뉴런 출력값을 0으로 만듦.\n",
    "- 네트워크가 제한된 representation을 가지고도 작동할 수 있게함.\n",
    "- Drop out을 사용하는 것이 여러 sub network들을 ensemble한 결과로 볼 수 있음\n",
    "\n",
    "<img src = './images/dropout.png' width= 300>\n",
    "\n",
    "\n",
    "- 학습을 할 때 랜덤하게 일정 뉴런의 출력값을 0으로 만들어 실제 테스트 시에는 이러한 randomness를 평균해주기 위해 drop확률 만큼을 출력값에 곱해준다.  \n",
    "$ E[a]=$  \n",
    "$=w_{1}x+w_{2}y = \\frac{1}{4}(w_{1}x+w_{2}y) + \\frac{1}{4}(w_{1}x+0*y)+\\frac{1}{4}(0*x+w_{2}y)+\\frac{1}{4}(0*x+0*y)$  \n",
    "$=\\frac{1}{2}(w_{1}x+w_{2}y)$\n",
    "- 네트워크의 일부분만 학습을 해 학습속도가 빠르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Early Stopping\n",
    "\n",
    "<img src = './images/early_stopping.png' width= 300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
